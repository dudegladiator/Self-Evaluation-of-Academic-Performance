{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiajS2s7ciJk"
      },
      "source": [
        "#Behavioral Slope\n",
        "The Behavioral Slope , a core aspect of the SMART GPA project, delves into student behavior patterns and their influence on academic performance. Utilizing the comprehensive Student Life dataset, this analysis aims to uncover trends in behaviors such as study habits, social interactions, and sleep routines. By assessing shifts and breakpoints in these behaviors, the analysis seeks to identify potential correlations with changes in GPA. With data sourced from sensors and smartphone apps, this exploration offers insights into students' multifaceted daily lives. By linking behavioral dynamics with academic outcomes, the analysis contributes to a deeper understanding of factors impacting student success.\n",
        "\n",
        "Paper Link = [Smart GPA](https://studentlife.cs.dartmouth.edu/smartgpa.pdf)\n",
        "Student Life Dataset = [Dataset]()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxPGYXsfeiXm"
      },
      "source": [
        "Upload  Kaggle API\n",
        "\n",
        "\n",
        "Download it from here(Kaggle JSON) -\n",
        "https://www.kaggle.com/settings/account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n55MEko4Youc",
        "outputId": "66d4c1e3-2c65-4bdb-8070-ab831e57581e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading student-life.zip to /content\n",
            "100% 390M/390M [00:18<00:00, 28.8MB/s]\n",
            "100% 390M/390M [00:18<00:00, 22.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Downloading Dataset\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d dartweichen/student-life --unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouPy1uGQb20C"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smeck7yFfHQ4"
      },
      "source": [
        "Creating A dataframe for Slopes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYqEwOivJzD4"
      },
      "outputs": [],
      "source": [
        "df1=pd.read_csv(\"/content/dataset/education/grades.csv\")\n",
        "uids=df1['uid'].tolist()\n",
        "AllSlopes=pd.DataFrame()\n",
        "AllSlopes['uids']=uids\n",
        "AllSlopes['gpa_all']=df1[' gpa all'].tolist()\n",
        "AllSlopes['Spring_gpa']=df1[' gpa 13s'].tolist()\n",
        "AllSlopes.set_index('uids', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMRUvJD0sUJ0"
      },
      "source": [
        "###Activity Slope"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsBXb2aTfVnJ"
      },
      "source": [
        "Heightened physical activity correlates with slope increase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJhGCVLEzTVk"
      },
      "outputs": [],
      "source": [
        "#Calculating Slopes for Whole Day\n",
        "def linear_regression_activity(df):\n",
        "  df = df.assign(timestamp=df['timestamp'].apply(lambda x: x.timestamp()))\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' activity inference']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIvDfmCikUie"
      },
      "outputs": [],
      "source": [
        "#Calculating Slopes during daytime\n",
        "def linear_regression_activity_day(df):\n",
        "  df=df[(df['timestamp'].dt.hour >= 9) & (df['timestamp'].dt.hour < 18)]\n",
        "  df = df.assign(timestamp=df['timestamp'].apply(lambda x: x.timestamp()))\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' activity inference']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pst_YfO-IlXp"
      },
      "outputs": [],
      "source": [
        "#Calculating Slopes during nighttime\n",
        "def linear_regression_activity_night(df):\n",
        "  df=df[(df['timestamp'].dt.hour >= 0) & (df['timestamp'].dt.hour < 9)]\n",
        "  df = df.assign(timestamp=df['timestamp'].apply(lambda x: x.timestamp()))\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' activity inference']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9lTu_MvIlPC"
      },
      "outputs": [],
      "source": [
        "#Calculating Slopes during evening\n",
        "def linear_regression_activity_evening(df):\n",
        "  df=df[(df['timestamp'].dt.hour >= 18) & (df['timestamp'].dt.hour < 24)]\n",
        "  df = df.assign(timestamp=df['timestamp'].apply(lambda x: x.timestamp()))\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' activity inference']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKgEVy9gpl-u"
      },
      "outputs": [],
      "source": [
        "#Calculating Activity Slope for each student\n",
        "for uid in uids:\n",
        "  file=\"/content/dataset/sensing/activity/activity_\"+uid+\".csv\"\n",
        "  try:\n",
        "    #Data Preprocessing\n",
        "    df = pd.read_csv(file)\n",
        "    df=df[df[' activity inference']!=3]\n",
        "    df.loc[:,'timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "    #Calculating Slopes\n",
        "    AllSlopes.loc[uid,'SlopeActivityTerm']=linear_regression_activity(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeActivityDayTerm']=linear_regression_activity_day(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeActivityNightTerm']=linear_regression_activity_night(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeActivityEveningTerm']=linear_regression_activity_evening(df)[0][0]\n",
        "    #Spliting data into Pre and Post\n",
        "    split_index = int(len(df) * 0.45)\n",
        "    AllSlopes.loc[uid,'SlopeActivityTermPre']=linear_regression_activity(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeActivityTermPost']=linear_regression_activity(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeActivityDayPre']=linear_regression_activity_day(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeActivityDayPost']=linear_regression_activity_day(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeActivityNightPre']=linear_regression_activity_night(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeActivityNightPost']=linear_regression_activity_night(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeActivityEveningPre']=linear_regression_activity_evening(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeActivityEveningPost']=linear_regression_activity_evening(df.iloc[split_index:])[0][0]\n",
        "  except:\n",
        "    continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2qHFXsfHMar"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFw5EgKQ3IM4"
      },
      "source": [
        "### Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z_3bZLDb2nw"
      },
      "outputs": [],
      "source": [
        "def linear_regression_audio(df):\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' audio inference']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW3Uy0hcXmjU"
      },
      "outputs": [],
      "source": [
        "def linear_regression_audio_day(df):\n",
        "  df=df[(df['timestamp'].dt.hour >= 9) & (df['timestamp'].dt.hour < 18)]\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' audio inference']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0hMol5cXqiO"
      },
      "outputs": [],
      "source": [
        "def linear_regression_audio_evening(df):\n",
        "  df=df[(df['timestamp'].dt.hour >= 18) & (df['timestamp'].dt.hour < 24)]\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' audio inference']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvtGs9jDXpDs"
      },
      "outputs": [],
      "source": [
        "def linear_regression_audio_night(df):\n",
        "  df=df[(df['timestamp'].dt.hour >= 0) & (df['timestamp'].dt.hour < 9)]\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' audio inference']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8jwpOFd4cW7"
      },
      "outputs": [],
      "source": [
        "for uid in uids:\n",
        "  file=\"/content/dataset/sensing/audio/audio_\"+uid+\".csv\"\n",
        "  try:\n",
        "    #Data Preprocessing\n",
        "    df = pd.read_csv(file)\n",
        "    df=df[df[' audio inference']!=3]\n",
        "    AllSlopes.loc[uid,'SlopeAudioTerm']=linear_regression_audio(df)[0][0]\n",
        "    #Data Preprocessing\n",
        "    df.loc[:,'timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "    #Calculating Slopes\n",
        "    AllSlopes.loc[uid,'SlopeAudioDayTerm']=linear_regression_audio_day(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeAudioNightTerm']=linear_regression_audio_night(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeAudioEveningTerm']=linear_regression_audio_evening(df)[0][0]\n",
        "    #Spliting data into Pre and Post\n",
        "    split_index = int(len(df) * 0.45)\n",
        "    AllSlopes.loc[uid,'SlopeAudioTermPre']=linear_regression_audio(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeAudioTermPost']=linear_regression_audio(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeAudioDayPre']=linear_regression_audio_day(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeAudioDayPost']=linear_regression_audio_day(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeAudioNightPre']=linear_regression_audio_night(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeAudioNightPost']=linear_regression_audio_night(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeAudioEveningPre']=linear_regression_audio_evening(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeAudioEveningPost']=linear_regression_audio_evening(df.iloc[split_index:])[0][0]\n",
        "  except:\n",
        "    continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjoC9jdTPC4G"
      },
      "source": [
        "###Conversation Duration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkHn4c7v5bMM"
      },
      "outputs": [],
      "source": [
        "def linear_regression_conversation_duration(df):\n",
        "  x=np.array(df['start_timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' end_timestamp']-df['start_timestamp']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmkAc9uNSYsd"
      },
      "outputs": [],
      "source": [
        "def linear_regression_conversation_duration_day(df):\n",
        "  df=df[(df['start_timestamp'].dt.hour >= 9) & (df['start_timestamp'].dt.hour < 18)]\n",
        "  x=np.array(df['start_timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' end_timestamp']-df['start_timestamp']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trPIyhOChF5R"
      },
      "outputs": [],
      "source": [
        "def linear_regression_conversation_duration_night(df):\n",
        "  df=df[(df['start_timestamp'].dt.hour >= 0) & (df['start_timestamp'].dt.hour < 9)]\n",
        "  x=np.array(df['start_timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' end_timestamp']-df['start_timestamp']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S04i5PJ9h04m"
      },
      "outputs": [],
      "source": [
        "def linear_regression_conversation_duration_evening(df):\n",
        "  df=df[(df['start_timestamp'].dt.hour >= 18) & (df['start_timestamp'].dt.hour < 24)]\n",
        "  x=np.array(df['start_timestamp']).reshape(-1,1)\n",
        "  y=np.array(df[' end_timestamp']-df['start_timestamp']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEwEhSzMPa9U"
      },
      "outputs": [],
      "source": [
        "for uid in uids:\n",
        "  file=\"/content/dataset/sensing/conversation/conversation_\"+uid+\".csv\"\n",
        "  try:\n",
        "    #Data Preprocessing\n",
        "    df = pd.read_csv(file)\n",
        "    #Calculating Slopes\n",
        "    AllSlopes.loc[uid,'SlopeConDurTerm']=linear_regression_conversation_duration(df)[0][0]\n",
        "    #data preprocessing\n",
        "    df['start_timestamp'] = pd.to_datetime(df['start_timestamp'], unit='s')\n",
        "    df[' end_timestamp'] = pd.to_datetime(df[' end_timestamp'], unit='s')\n",
        "    AllSlopes.loc[uid,'SlopeConDurDayTerm']=linear_regression_conversation_duration_day(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConDurNightTerm']=linear_regression_conversation_duration_night(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConDurEveningTerm']=linear_regression_conversation_duration_evening(df)[0][0]\n",
        "    #Spliting data into Pre and Post\n",
        "    split_index = int(len(df) * 0.45)\n",
        "    AllSlopes.loc[uid,'SlopeConDurTermPre']=linear_regression_conversation_duration(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConDurTermPost']=linear_regression_conversation_duration(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConDurDayPre']=linear_regression_conversation_duration_day(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConDurDayPost']=linear_regression_conversation_duration_day(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConDurNightPre']=linear_regression_conversation_duration_night(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConDurNightPost']=linear_regression_conversation_duration_night(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConDurEveningPre']=linear_regression_conversation_duration_evening(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConDurEveningPost']=linear_regression_conversation_duration_evening(df.iloc[split_index:])[0][0]\n",
        "  except:\n",
        "    continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z7NfMTSRlkE"
      },
      "source": [
        "###Conversation frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvsNBp0YVJvN"
      },
      "outputs": [],
      "source": [
        "def linear_regression_conversation_freq(df):\n",
        "  # Count the number of rows for each date\n",
        "  daily_counts = df.groupby('date').size().reset_index(name='counts')\n",
        "  daily_counts['date'] = daily_counts['date'].map(datetime.datetime.toordinal)\n",
        "  x=np.array(daily_counts[\"date\"]).reshape(-1,1)\n",
        "  y=np.array(daily_counts[\"counts\"]).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "860S7UrXVJrd"
      },
      "outputs": [],
      "source": [
        "def linear_regression_conversation_freq_day(df):\n",
        "  df=df[(df['start_timestamp'].dt.hour >= 9) & (df['start_timestamp'].dt.hour < 18)]\n",
        "  # Count the number of rows for each date\n",
        "  daily_counts = df.groupby('date').size().reset_index(name='counts')\n",
        "  daily_counts['date'] = daily_counts['date'].map(datetime.datetime.toordinal)\n",
        "  x=np.array(daily_counts[\"date\"]).reshape(-1,1)\n",
        "  y=np.array(daily_counts[\"counts\"]).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_KFVDEir6fq"
      },
      "outputs": [],
      "source": [
        "def linear_regression_conversation_freq_evening(df):\n",
        "  df=df[(df['start_timestamp'].dt.hour >= 18) & (df['start_timestamp'].dt.hour < 24)]\n",
        "  # Count the number of rows for each date\n",
        "  daily_counts = df.groupby('date').size().reset_index(name='counts')\n",
        "  daily_counts['date'] = daily_counts['date'].map(datetime.datetime.toordinal)\n",
        "  x=np.array(daily_counts[\"date\"]).reshape(-1,1)\n",
        "  y=np.array(daily_counts[\"counts\"]).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlUouaQ7jsDv"
      },
      "outputs": [],
      "source": [
        "def linear_regression_conversation_freq_night(df):\n",
        "  df=df[(df['start_timestamp'].dt.hour >= 0) & (df['start_timestamp'].dt.hour < 9)]\n",
        "  # Count the number of rows for each date\n",
        "  daily_counts = df.groupby('date').size().reset_index(name='counts')\n",
        "  daily_counts['date'] = daily_counts['date'].map(datetime.datetime.toordinal)\n",
        "  x=np.array(daily_counts[\"date\"]).reshape(-1,1)\n",
        "  y=np.array(daily_counts[\"counts\"]).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hk7W0xamjsBW"
      },
      "outputs": [],
      "source": [
        "for uid in uids:\n",
        "  file=\"/content/dataset/sensing/conversation/conversation_\"+uid+\".csv\"\n",
        "  try:\n",
        "    #data preprocessing\n",
        "    df = pd.read_csv(file)\n",
        "    df['start_timestamp'] = pd.to_datetime(df['start_timestamp'], unit='s')\n",
        "    df[' end_timestamp'] = pd.to_datetime(df[' end_timestamp'], unit='s')\n",
        "    df['date'] = df['start_timestamp'].dt.date\n",
        "    #slope\n",
        "    AllSlopes.loc[uid,'SlopeConFreqTerm']=linear_regression_conversation_freq(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConFreqDayTerm']=linear_regression_conversation_freq_day(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConFreqNightTerm']=linear_regression_conversation_freq_night(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConFreqEveningTerm']=linear_regression_conversation_freq_evening(df)[0][0]\n",
        "    #Spliting data into Pre and Post\n",
        "    split_index = int(len(df) * 0.45)\n",
        "    AllSlopes.loc[uid,'SlopeConFreqTermPre']=linear_regression_conversation_freq(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConFreqTermPost']=linear_regression_conversation_freq(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConFreqDayPre']=linear_regression_conversation_freq_day(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConFreqDayPost']=linear_regression_conversation_freq_day(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConFreqNightPre']=linear_regression_conversation_freq_night(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConFreqNightPost']=linear_regression_conversation_freq_night(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConFreqEveningPre']=linear_regression_conversation_freq_evening(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeConFreqEveningPost']=linear_regression_conversation_freq_evening(df.iloc[split_index:])[0][0]\n",
        "  except:\n",
        "    continue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne7yaFt_wZMC"
      },
      "source": [
        "###Indoor mobility - Wifi Location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOF3AxKHuCLC"
      },
      "outputs": [],
      "source": [
        "def linear_regression_mobility(df):\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df['location']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1ZSj3-48ztD"
      },
      "outputs": [],
      "source": [
        "def linear_regression_mobility_day(df):\n",
        "  df=df[(df['timestamp'].dt.hour >= 9) & (df['timestamp'].dt.hour < 18)]\n",
        "  df = df.assign(timestamp=df['timestamp'].apply(lambda x: x.timestamp()))\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df['location']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_-bWyi0ZVH_"
      },
      "outputs": [],
      "source": [
        "def linear_regression_mobility_evening(df):\n",
        "  df=df[(df['timestamp'].dt.hour >= 18) & (df['timestamp'].dt.hour < 24)]\n",
        "  df = df.assign(timestamp=df['timestamp'].apply(lambda x: x.timestamp()))\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df['location']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo8Qz7WS8QQ4"
      },
      "outputs": [],
      "source": [
        "def linear_regression_mobility_night(df):\n",
        "  df=df[(df['timestamp'].dt.hour >= 0) & (df['timestamp'].dt.hour < 9)]\n",
        "  df = df.assign(timestamp=df['timestamp'].apply(lambda x: x.timestamp()))\n",
        "  x=np.array(df['timestamp']).reshape(-1,1)\n",
        "  y=np.array(df['location']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iV66Jmzjr2Z"
      },
      "outputs": [],
      "source": [
        "for uid in uids:\n",
        "  file=\"/content/dataset/sensing/wifi_location/wifi_location_\"+uid+\".csv\"\n",
        "  try:\n",
        "    #data preprocessing\n",
        "    df = pd.read_csv(file)\n",
        "    df=df.reset_index()\n",
        "    df.drop('location',axis=1,inplace=True)\n",
        "    df.rename(columns={'index':'timestamp','time':'location'},inplace=True)\n",
        "    df['location'] = df['location'].astype(str)\n",
        "    df.loc[df['location'].str[:2].isin(['in']), 'location'] = 1\n",
        "    df.loc[df['location'].str[:4].isin(['near']), 'location'] = 0\n",
        "    #calculating Slopes\n",
        "    AllSlopes.loc[uid,'SlopeMobilityTerm']=linear_regression_mobility(df)[0][0]\n",
        "    df.loc[:,'timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "    AllSlopes.loc[uid,'SlopeMobilityDayTerm']=linear_regression_mobility_day(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeMobilityNightTerm']=linear_regression_mobility_night(df)[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeMobilityEveningTerm']=linear_regression_mobility_evening(df)[0][0]\n",
        "    #Spliting data into Pre and Post\n",
        "    split_index = int(len(df) * 0.45)\n",
        "    AllSlopes.loc[uid,'SlopeMobilityTermPre']=linear_regression_mobility(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeMobilityTermPost']=linear_regression_mobility(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeMobilityDayPre']=linear_regression_mobility_day(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeMobilityDayPost']=linear_regression_mobility_day(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeMobilityNightPre']=linear_regression_mobility_night(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeMobilityNightPost']=linear_regression_mobility_night(df.iloc[split_index:])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeMobilityEveningPre']=linear_regression_mobility_evening(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopeMobilityEveningPost']=linear_regression_mobility_evening(df.iloc[split_index:])[0][0]\n",
        "  except:\n",
        "    continue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7GfCJLd9Qfm"
      },
      "source": [
        "###Sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nToVX_Ud8IaW"
      },
      "outputs": [],
      "source": [
        "def linear_regression_sleep(df):\n",
        "  x=np.array(df['resp_time']).reshape(-1,1)\n",
        "  y=np.array(df['hour']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxkPww8FGGE7"
      },
      "outputs": [],
      "source": [
        "for uid in uids:\n",
        "  file=\"/content/dataset/EMA/response/Sleep/Sleep_\"+uid+\".json\"\n",
        "  try:\n",
        "    #data preprocessing\n",
        "    df=pd.read_json(file)\n",
        "    if uid!=\"u57\" and uid!=\"u59\":\n",
        "      df.drop(['null','location'],axis=1,inplace=True)\n",
        "    df=df.dropna()\n",
        "    #calculating Slopes\n",
        "    AllSlopes.loc[uid,'SlopeSleepTerm']=linear_regression_sleep(df)[0][0]\n",
        "    #Spliting data into Pre and Post\n",
        "    start_date = df['resp_time'].min()\n",
        "    interval_length = pd.DateOffset(weeks=3)\n",
        "    split_date = start_date + interval_length\n",
        "    interval_1 = df[(df['resp_time'] >= start_date) & (df['resp_time'] < split_date)]\n",
        "    interval_2 = df[df['resp_time'] >= split_date]\n",
        "    #calculating Slopes\n",
        "    if len(interval_1)==0:\n",
        "      AllSlopes.loc[uid,'SlopeSleepTermPre']=np.nan\n",
        "    else:\n",
        "      AllSlopes.loc[uid,'SlopeSleepTermPre']=linear_regression_sleep(interval_1)[0][0]\n",
        "    if len(interval_2)==0:\n",
        "      AllSlopes.loc[uid,'SlopeSleepTermPost']=np.nan\n",
        "    else:\n",
        "      AllSlopes.loc[uid,'SlopeSleepTermPost']=linear_regression_sleep(interval_2)[0][0]\n",
        "  except:\n",
        "    continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO-rZLCXIzXE"
      },
      "source": [
        "###Stress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5DfK-q1MQ5Z"
      },
      "source": [
        "1 - feeling great , 2 - feeling good, 3 - little stresses , 4 - definately stress , 5 -  stressed out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXCgRMr68IIX"
      },
      "outputs": [],
      "source": [
        "def linear_regression_stress(df):\n",
        "  x=np.array(df['resp_time']).reshape(-1,1)\n",
        "  y=np.array(df['level']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pwKVjrALshO"
      },
      "outputs": [],
      "source": [
        "for uid in uids:\n",
        "  file=\"/content/dataset/EMA/response/Stress/Stress_\"+uid+\".json\"\n",
        "  try:\n",
        "    #Data preprocessing\n",
        "    df=pd.read_json(file)\n",
        "    df.drop([\"null\",'location'],axis=1,inplace=True)\n",
        "    df=df.dropna()\n",
        "    df.replace({1:3,2:4,3:5,4:2,5:1},inplace=True)\n",
        "    #Calculating Slopes\n",
        "    AllSlopes.loc[uid,'SlopeStressTerm']=linear_regression_stress(df)[0][0]\n",
        "    #Spliting data into Pre and Post\n",
        "    start_date = df['resp_time'].min()\n",
        "    interval_length = pd.DateOffset(weeks=3) # Setting the interval to 3 weeks\n",
        "    split_date = start_date + interval_length\n",
        "    interval_1 = df[(df['resp_time'] >= start_date) & (df['resp_time'] < split_date)]\n",
        "    interval_2 = df[df['resp_time'] >= split_date]\n",
        "    #Calculating Slopes\n",
        "    if len(interval_1)==0:\n",
        "      AllSlopes.loc[uid,'SlopeStressTermPre']=np.nan\n",
        "    else:\n",
        "      AllSlopes.loc[uid,'SlopeStressTermPre']=linear_regression_stress(interval_1)[0][0]\n",
        "    if len(interval_2)==0:\n",
        "      AllSlopes.loc[uid,'SlopeStressTermPost']=np.nan\n",
        "    else:\n",
        "      AllSlopes.loc[uid,'SlopeStressTermPost']=linear_regression_stress(interval_2)[0][0]\n",
        "  except:\n",
        "    continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ENMt_6NOy8B"
      },
      "source": [
        "###PAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swoBzcbyMh_K"
      },
      "outputs": [],
      "source": [
        "def linear_regression_pam(df):\n",
        "  x=np.array(df['resp_time']).reshape(-1,1)\n",
        "  y=np.array(df['picture_idx']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICXnL2CkMh8S"
      },
      "outputs": [],
      "source": [
        "for uid in uids:\n",
        "  file=\"/content/dataset/EMA/response/PAM/PAM_\"+uid+\".json\"\n",
        "  try:\n",
        "    df=pd.read_json(file)\n",
        "    df=df.dropna()\n",
        "    AllSlopes.loc[uid,'SlopePAMTerm']=linear_regression_pam(df)[0][0]\n",
        "    #Spliting data into Pre and Post\n",
        "    start_date = df['resp_time'].min()\n",
        "    interval_length = pd.DateOffset(weeks=3)\n",
        "    split_date = start_date + interval_length\n",
        "    interval_1 = df[(df['resp_time'] >= start_date) & (df['resp_time'] < split_date)]\n",
        "    interval_2 = df[df['resp_time'] >= split_date]\n",
        "    #Calculating Slopes\n",
        "    if len(interval_1)==0:\n",
        "      AllSlopes.loc[uid,'SlopePAMPre']=np.nan\n",
        "    else:\n",
        "      AllSlopes.loc[uid,'SlopePAMPre']=linear_regression_pam(interval_1)[0][0]\n",
        "    if len(interval_2)==0:\n",
        "      AllSlopes.loc[uid,'SlopePAMPost']=np.nan\n",
        "    else:\n",
        "      AllSlopes.loc[uid,'SlopePAMPost']=linear_regression_pam(interval_2)[0][0]\n",
        "  except:\n",
        "    continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck7k44TEaVLv"
      },
      "source": [
        "###Class Hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDXkkm2awQ5B"
      },
      "outputs": [],
      "source": [
        "def linear_regression_class(df):\n",
        "  x=np.array(df['resp_time']).reshape(-1,1)\n",
        "  y=np.array(df['hours']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yaVdPYZwQ1R"
      },
      "outputs": [],
      "source": [
        "for uid in uids:\n",
        "    file=\"/content/dataset/EMA/response/Class/Class_\"+uid+\".json\"\n",
        "\n",
        "    df=pd.read_json(file)\n",
        "    if uid!=\"u57\" and uid!=\"u59\":\n",
        "      df.drop([\"null\",'location',\"due\",\"course_id\"],axis=1,inplace=True)\n",
        "    df=df.dropna()\n",
        "    AllSlopes.loc[uid,'SlopeClassTerm']=linear_regression_class(df)[0][0]\n",
        "    #Spliting data into Pre and Post\n",
        "    start_date = df['resp_time'].min()\n",
        "    interval_length = pd.DateOffset(weeks=3)\n",
        "    split_date = start_date + interval_length\n",
        "    interval_1 = df[(df['resp_time'] >= start_date) & (df['resp_time'] < split_date)]\n",
        "    interval_2 = df[df['resp_time'] >= split_date]\n",
        "    #Calculating Slopes\n",
        "    if len(interval_1)==0:\n",
        "      AllSlopes.loc[uid,'SlopeClassPre']=np.nan\n",
        "    else:\n",
        "      AllSlopes.loc[uid,'SlopeClassPre']=linear_regression_class(interval_1)[0][0]\n",
        "    if len(interval_2)==0:\n",
        "      AllSlopes.loc[uid,'SlopeClassPost']=np.nan\n",
        "    else:\n",
        "      AllSlopes.loc[uid,'SlopeClassPost']=linear_regression_class(interval_2)[0][0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKcwmD9qaYqU"
      },
      "source": [
        "###Phone Charge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmZcYpMBwQs3"
      },
      "outputs": [],
      "source": [
        "def linear_regression_phonecharge(df):\n",
        "  x=np.array(df['start']).reshape(-1,1)\n",
        "  y=np.array(df['end']-df['start']).reshape(-1,1)\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(x,y)\n",
        "  return reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3Re48YnwQqG"
      },
      "outputs": [],
      "source": [
        "for uid in uids:\n",
        "    file=\"/content/dataset/sensing/phonecharge/phonecharge_\"+uid+\".csv\"\n",
        "    df=pd.read_csv(file)\n",
        "    AllSlopes.loc[uid,'SlopePhonechargeTerm']=linear_regression_phonecharge(df)[0][0]\n",
        "    #Spliting data into Pre and Post\n",
        "    split_index=int(len(df)*0.45)\n",
        "    #Calculating Slopes\n",
        "    AllSlopes.loc[uid,'SlopePhonechargePre']=linear_regression_phonecharge(df.iloc[:split_index])[0][0]\n",
        "    AllSlopes.loc[uid,'SlopePhonechargePost']=linear_regression_phonecharge(df.iloc[split_index:])[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeYXTQT8aa2E"
      },
      "source": [
        "###Panas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qqc7Ber9wQnT"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/dataset/survey/panas.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRmaauA3wQkj"
      },
      "outputs": [],
      "source": [
        "for index,rows in df.iterrows():\n",
        "  if rows['uid'] in uids and rows[\"type\"]=='pre':\n",
        "    AllSlopes.loc[rows['uid'],'PositiveScorePre']=rows[\"Interested\"]+rows[\"Strong\"]+rows[\"Enthusiastic\"]+rows[\"Proud\"]+rows[\"Alert\"]+rows[\"Inspired\"]+rows[\"Determined \"]+rows[\"Attentive\"]+rows[\"Active \"]\n",
        "    AllSlopes.loc[rows['uid'],'NegativeScorePre']=rows['Distressed']+rows['Upset']+rows['Guilty']+rows['Scared']+rows['Hostile ']+rows['Irritable']+rows['Nervous']+rows['Jittery']+rows['Afraid ']\n",
        "  if rows['uid'] in uids and rows[\"type\"]=='post':\n",
        "    AllSlopes.loc[rows['uid'],'PositiveScorePost']=rows[\"Interested\"]+rows[\"Strong\"]+rows[\"Enthusiastic\"]+rows[\"Proud\"]+rows[\"Alert\"]+rows[\"Inspired\"]+rows[\"Determined \"]+rows[\"Attentive\"]+rows[\"Active \"]\n",
        "    AllSlopes.loc[rows['uid'],'NegativeScorePost']=rows['Distressed']+rows['Upset']+rows['Guilty']+rows['Scared']+rows['Hostile ']+rows['Irritable']+rows['Nervous']+rows['Jittery']+rows['Afraid ']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnrQJ_edhfcd"
      },
      "source": [
        "###PHQ9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEBDsN5_wQfa"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/dataset/survey/PHQ-9.csv\")\n",
        "df.drop([\"Response\"],axis=1,inplace=True)\n",
        "df.replace({\"Not at all\":0,\"Several days\":1,\"More than half the days\":2,\"Nearly every day\":3},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MgWo--KwQcp"
      },
      "outputs": [],
      "source": [
        "for index,rows in df.iterrows():\n",
        "  if rows['uid'] in uids and rows['type']=='pre':\n",
        "    AllSlopes.loc[rows['uid'],'PHQ9ScorePre']=df.iloc[index,2]+df.iloc[index,3]+df.iloc[index,4]+df.iloc[index,5]+df.iloc[index,6]+df.iloc[index,7]+df.iloc[index,8]+df.iloc[index,9]+df.iloc[index,10]\n",
        "  if rows['uid'] in uids and rows['type']=='post':\n",
        "    AllSlopes.loc[rows['uid'],'PHQ9ScorePost']=df.iloc[index,2]+df.iloc[index,3]+df.iloc[index,4]+df.iloc[index,5]+df.iloc[index,6]+df.iloc[index,7]+df.iloc[index,8]+df.iloc[index,9]+df.iloc[index,10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCHeDgXemgBO"
      },
      "source": [
        "###Loneliness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVr2gUIHeBFV"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/dataset/survey/LonelinessScale.csv\")\n",
        "df.replace({\"Never\":0,\"Rarely\":1,\"Sometimes\":2,\"Often\":3},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDgBURXOwQZx"
      },
      "outputs": [],
      "source": [
        "for index,rows in df.iterrows():\n",
        "  if rows['uid'] in uids and rows['type']=='pre':\n",
        "    AllSlopes.loc[rows['uid'],'LonelinessScorePre']=df.iloc[index,2]+df.iloc[index,3]+df.iloc[index,4]+df.iloc[index,5]+df.iloc[index,6]+df.iloc[index,7]+df.iloc[index,8]+df.iloc[index,9]+df.iloc[index,10]+df.iloc[index,11]+df.iloc[index,12]+df.iloc[index,13]+df.iloc[index,14]+df.iloc[index,15]+df.iloc[index,16]+df.iloc[index,17]+df.iloc[index,18]+df.iloc[index,19]+ df.iloc[index,20] + df.iloc[index,21]\n",
        "  if rows['uid'] in uids and rows['type']=='post':\n",
        "    AllSlopes.loc[rows['uid'],'LonelinessScorePost']=df.iloc[index,2]+df.iloc[index,3]+df.iloc[index,4]+df.iloc[index,5]+df.iloc[index,6]+df.iloc[index,7]+df.iloc[index,8]+df.iloc[index,9]+df.iloc[index,10]+df.iloc[index,11]+df.iloc[index,12]+df.iloc[index,13]+df.iloc[index,14]+df.iloc[index,15]+df.iloc[index,16]+df.iloc[index,17]+df.iloc[index,18]+df.iloc[index,19]+ df.iloc[index,20] + df.iloc[index,21]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrr3fojokHOE"
      },
      "source": [
        "###All Slopes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br4ry-K-kGAk"
      },
      "outputs": [],
      "source": [
        "AllSlopes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEajEL3ykMk6"
      },
      "outputs": [],
      "source": [
        "AllSlopes.to_csv(\"AllSlopes.csv\",index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MMRUvJD0sUJ0",
        "sFw5EgKQ3IM4",
        "IjoC9jdTPC4G",
        "-Z7NfMTSRlkE",
        "Ne7yaFt_wZMC",
        "_7GfCJLd9Qfm",
        "ZO-rZLCXIzXE",
        "9ENMt_6NOy8B",
        "Ck7k44TEaVLv",
        "dKcwmD9qaYqU",
        "eeYXTQT8aa2E",
        "BnrQJ_edhfcd",
        "WCHeDgXemgBO",
        "4nWbyzV-wL-J",
        "l5vJDwghhh64",
        "STF6ycJ3IfCR"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
